{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TongmengXie/GNN/blob/main/Node_pred_GCN_GNNExplainer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OCK7krJdp4o8"
      },
      "source": [
        "# Setup\n",
        " installation of PyG on Colab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2vkP8pA1qBE5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8de8c97d-2ae5-4788-c8c7-29c9a9adb905"
      },
      "source": [
        "import torch\n",
        "import os\n",
        "print(\"PyTorch has version {}\".format(torch.__version__))\n",
        "!python --version\n",
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch has version 2.7.0+cu126\n",
            "Python 3.11.12\n",
            "Fri May  9 14:49:26 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   71C    P0             29W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L6d22O6DqGSZ"
      },
      "source": [
        "Make sure the version of torch matches cuda, torch sparse and torch vision. More information can be found on the [PyG's installation page](https://pytorch-geometric.readthedocs.io/en/latest/notes/installation.html)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zr8hfxJ-qRg2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1563953-72f6-400e-da59-03c251c9904c"
      },
      "source": [
        "# Install torch geometric\n",
        "\n",
        "# !pip install torch-scatter -f https://pytorch-geometric.com/whl/torch-1.13.1+cu116.html\n",
        "# !wget https://pytorch-geometric.com/whl/torch-1.13.1+cu116/torch_scatter-2.0.9-cp37-cp37m-linux_x86_64.whl\n",
        "# !pip install torch_scatter-2.0.9-cp37-cp37m-linux_x86_64.whl\n",
        "# !wget https://pytorch-geometric.com/whl/torch-1.13.1+cu116/torch_sparse-0.6.13-cp37-cp37m-linux_x86_64.whl\n",
        "# !pip install torch-sparse -f https://pytorch-geometric.com/whl/torch-1.13.1+cu116.html\n",
        "\n",
        "!wget torch_scatter-2.1.2+pt26cu124-cp311-cp311-linux_x86_64.whl\n",
        "!pip install torch-scatter -f https://pytorch-geometric.com/whl/torch-1.13.1+cu116.html\n",
        "!wget torch_sparse-0.6.18+pt26cu124-cp311-cp311-linux_x86_64.whl\n",
        "!pip install torch-sparse -f https://pytorch-geometric.com/whl/torch-2.6.0+cu124.html\n",
        "!pip install ogb --upgrade"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-05-09 14:49:27--  http://torch_scatter-2.1.2+pt26cu124-cp311-cp311-linux_x86_64.whl/\n",
            "Resolving torch_scatter-2.1.2+pt26cu124-cp311-cp311-linux_x86_64.whl (torch_scatter-2.1.2+pt26cu124-cp311-cp311-linux_x86_64.whl)... failed: Name or service not known.\n",
            "wget: unable to resolve host address ‘torch_scatter-2.1.2+pt26cu124-cp311-cp311-linux_x86_64.whl’\n",
            "Looking in links: https://pytorch-geometric.com/whl/torch-1.13.1+cu116.html\n",
            "Requirement already satisfied: torch-scatter in /usr/local/lib/python3.11/dist-packages (2.1.2)\n",
            "--2025-05-09 14:49:33--  http://torch_sparse-0.6.18+pt26cu124-cp311-cp311-linux_x86_64.whl/\n",
            "Resolving torch_sparse-0.6.18+pt26cu124-cp311-cp311-linux_x86_64.whl (torch_sparse-0.6.18+pt26cu124-cp311-cp311-linux_x86_64.whl)... failed: Name or service not known.\n",
            "wget: unable to resolve host address ‘torch_sparse-0.6.18+pt26cu124-cp311-cp311-linux_x86_64.whl’\n",
            "Looking in links: https://pytorch-geometric.com/whl/torch-2.6.0+cu124.html\n",
            "Requirement already satisfied: torch-sparse in /usr/local/lib/python3.11/dist-packages (0.6.18+pt26cu124)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from torch-sparse) (1.15.3)\n",
            "Requirement already satisfied: numpy<2.5,>=1.23.5 in /usr/local/lib/python3.11/dist-packages (from scipy->torch-sparse) (2.2.5)\n",
            "Requirement already satisfied: ogb in /usr/local/lib/python3.11/dist-packages (1.3.6)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from ogb) (2.7.0)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.11/dist-packages (from ogb) (2.2.5)\n",
            "Requirement already satisfied: tqdm>=4.29.0 in /usr/local/lib/python3.11/dist-packages (from ogb) (4.67.1)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from ogb) (1.6.1)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from ogb) (2.2.3)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from ogb) (1.17.0)\n",
            "Requirement already satisfied: urllib3>=1.24.0 in /usr/local/lib/python3.11/dist-packages (from ogb) (2.4.0)\n",
            "Requirement already satisfied: outdated>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from ogb) (0.2.2)\n",
            "Requirement already satisfied: setuptools>=44 in /usr/local/lib/python3.11/dist-packages (from outdated>=0.2.0->ogb) (80.3.1)\n",
            "Requirement already satisfied: littleutils in /usr/local/lib/python3.11/dist-packages (from outdated>=0.2.0->ogb) (0.2.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from outdated>=0.2.0->ogb) (2.32.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24.0->ogb) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24.0->ogb) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24.0->ogb) (2025.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.20.0->ogb) (1.15.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.20.0->ogb) (1.5.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.20.0->ogb) (3.6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->ogb) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->ogb) (4.13.2)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->ogb) (1.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->ogb) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->ogb) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->ogb) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->ogb) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->ogb) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->ogb) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->ogb) (9.5.1.17)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->ogb) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->ogb) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->ogb) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->ogb) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->ogb) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->ogb) (0.6.3)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.26.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->ogb) (2.26.2)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->ogb) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->ogb) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->ogb) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.3.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->ogb) (3.3.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy>=1.13.3->torch>=1.6.0->ogb) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.6.0->ogb) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->outdated>=0.2.0->ogb) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->outdated>=0.2.0->ogb) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->outdated>=0.2.0->ogb) (2025.4.26)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nwwq0nSdmsOL"
      },
      "source": [
        "# 1) PyTorch Geometric (Datasets and Data)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sf7vUmdNKCjA"
      },
      "source": [
        "PyTorch Geometric has two classes for storing and/or transforming graphs into tensor format. One is `torch_geometric.datasets`, which contains a variety of common graph datasets. Another is `torch_geometric.data`, which provides the data handling of graphs in PyTorch tensors.\n",
        "\n",
        "In this section, we will learn how to use `torch_geometric.datasets` and `torch_geometric.data` together."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ic-o1P3r6hr2"
      },
      "source": [
        "## PyG Datasets\n",
        "\n",
        "The `torch_geometric.datasets` class has many common graph datasets. Here we will explore its usage through one example dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zT5qca3x6XpG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8de7dd2c-03a7-409e-e5b3-0091fca8d0f4"
      },
      "source": [
        "import torch_geometric.transforms as T\n",
        "import torch_geometric\n",
        "from torch_geometric.data.data import DataTensorAttr, DataEdgeAttr\n",
        "from torch_geometric.data.storage import GlobalStorage\n",
        "from ogb.nodeproppred import PygNodePropPredDataset\n",
        "\n",
        "import torch.serialization\n",
        "import os\n",
        "torch.serialization.add_safe_globals([DataEdgeAttr, DataTensorAttr, GlobalStorage])\n",
        "# TORCH_FORCE_NO_WEIGHTS_ONLY_LOAD=1\n",
        "# torch.serialization.add_safe_globals({'DataEdgeAttr': DataEdgeAttr})\n",
        "\n",
        "dataset_name = 'ogbn-arxiv'\n",
        "# dataset = PygNodePropPredDataset(name=dataset_name, transform=T.ToSparseTensor())\n",
        "# with torch.serialization.safe_globals([torch_geometric.data.data.DataEdgeAttr]) as context:\n",
        "dataset = PygNodePropPredDataset(name=dataset_name)\n",
        "print('The {} dataset has {} graph'.format(dataset_name, len(dataset)))\n",
        "data = dataset[0]\n",
        "print(data)\n",
        "\n",
        "# dataset_name = 'ogbn-arxiv'\n",
        "# dataset = PygNodePropPredDataset(name=dataset_name, transform=T.ToSparseTensor())\n",
        "# data = torch.load(dataset.processed_paths[0], weights_only=False)\n",
        "# print(data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch_geometric/typing.py:86: UserWarning: An issue occurred while importing 'torch-scatter'. Disabling its usage. Stacktrace: /usr/local/lib/python3.11/dist-packages/torch_scatter/_version_cuda.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKSsb\n",
            "  warnings.warn(f\"An issue occurred while importing 'torch-scatter'. \"\n",
            "/usr/local/lib/python3.11/dist-packages/torch_geometric/typing.py:124: UserWarning: An issue occurred while importing 'torch-sparse'. Disabling its usage. Stacktrace: /usr/local/lib/python3.11/dist-packages/torch_sparse/_version_cuda.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKSsb\n",
            "  warnings.warn(f\"An issue occurred while importing 'torch-sparse'. \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ENZYMES(600)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8iF_Kyqr_JbY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9166144c-fe39-48f7-d792-334b7d88d792"
      },
      "source": [
        "# What is the number of classes and number of features in the dataset\n",
        "def get_num_classes(pyg_dataset):\n",
        "  num_classes = 0\n",
        "  num_classes = pyg_dataset.num_classes\n",
        "  return num_classes\n",
        "\n",
        "def get_num_features(pyg_dataset):\n",
        "  num_features = 0\n",
        "  num_classes = pyg_dataset.num_features\n",
        "\n",
        "\n",
        "  return num_features\n",
        "\n",
        "num_classes = get_num_classes(pyg_dataset)\n",
        "num_features = get_num_features(pyg_dataset)\n",
        "print(\"{} dataset has {} classes\".format(name, num_classes))\n",
        "print(\"{} dataset has {} features\".format(name, num_features))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ENZYMES dataset has 6 classes\n",
            "ENZYMES dataset has 0 features\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rwKbzhHUAckZ"
      },
      "source": [
        "## PyG Data\n",
        "\n",
        "Each PyG dataset stores a list of `torch_geometric.data.Data` objects, where each `torch_geometric.data.Data` object represents a graph. We can easily get the `Data` object by indexing into the dataset.\n",
        "\n",
        "For more information such as what is stored in the `Data` object, please refer to the [documentation](https://pytorch-geometric.readthedocs.io/en/latest/modules/data.html#torch_geometric.data.Data)."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# What is the number of classes and number of features in the\n",
        "num_classes = get_num_classes(pyg_dataset)\n",
        "num_features = get_num_features(pyg_dataset)\n",
        "print(\"{} dataset has {} classes\".format(name, num_classes))\n",
        "print(\"{} dataset has {} features\".format(name, num_features))\n",
        "\n",
        "# How many edges does the graph with index 200 have?\n",
        "pyg_dataset[200].num_edges\n",
        "pyg_dataset[200].contains_isolated_nodes() # False"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aSU1nR5Nx5_D",
        "outputId": "7cb9bb84-12e8-4843-bfc5-918141441897"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch_geometric/deprecation.py:26: UserWarning: 'contains_isolated_nodes' is deprecated, use 'has_isolated_nodes' instead\n",
            "  warnings.warn(out)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f5m2DOfhBtWv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1dc2530a-bcc3-47ba-f438-8f1cc8981f34"
      },
      "source": [
        "def get_graph_num_edges(pyg_dataset, idx):\n",
        "\n",
        "  num_edges = 0\n",
        "\n",
        "\n",
        "  edges = []\n",
        "  for edge in pyg_dataset[200].to_dict()['edge_index'].T:\n",
        "    if (list(edge) not in edges) & ([edge[1], edge[0]] not in edges):\n",
        "      edges.append(list(edge))\n",
        "  num_edges = len(edges)\n",
        "\n",
        "\n",
        "  return num_edges\n",
        "\n",
        "# find out the edges connected to one node\n",
        "idx = 200\n",
        "num_edges = get_graph_num_edges(pyg_dataset, idx)\n",
        "print('Graph with index {} has {} edges'.format(idx, num_edges))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Graph with index 200 has 53 edges\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AXa7yIG4E0Fp"
      },
      "source": [
        "# 2) Open Graph Benchmark (OGB)\n",
        "\n",
        "The Open Graph Benchmark (OGB) is a collection of realistic, large-scale, and diverse benchmark datasets for machine learning on graphs. Its datasets are automatically downloaded, processed, and split using the OGB Data Loader. The model performance can then be evaluated by using the OGB Evaluator in a unified manner."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cw0xZJKZI-n3"
      },
      "source": [
        "## Question 4: How many features are in the ogbn-arxiv graph? (5 points)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZP844_nT2ZJl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cdfbd10f-4b73-45a7-d17f-e7e1e1e20b26"
      },
      "source": [
        "def graph_num_features(data):\n",
        "\n",
        "  num_features = 0\n",
        "  num_features = data.num_features\n",
        "\n",
        "  return num_features\n",
        "\n",
        "# How many features are in the ogbn-arxiv graph?\n",
        "num_features = graph_num_features(data)\n",
        "print('The graph has {} features'.format(num_features))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The graph has 128 features\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.num_edge_features, data.num_node_features"
      ],
      "metadata": {
        "id": "Ct8vlxhamo4k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3df8351-e008-4042-fd52-4a516afd1054"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0, 128)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9DP_yEQZ0NVW"
      },
      "source": [
        "# 3) GNN: Node Property Prediction\n",
        "\n",
        "In this section we will build our first graph neural network using PyTorch Geometric. Then we will apply it to the task of node property prediction (node classification).\n",
        "\n",
        "Specifically, we will use GCN as the foundation for your graph neural network ([Kipf et al. (2017)](https://arxiv.org/pdf/1609.02907.pdf)). To do so, we will work with PyG's built-in `GCNConv` layer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O4CcOUEoInjD"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-DCtgcHpGIpd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "14aea8f5-9222-4176-d914-e9f4e4dd5f84"
      },
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "import torch.nn.functional as F\n",
        "print(torch.__version__)\n",
        "\n",
        "# The PyG built-in GCNConv\n",
        "from torch_geometric.nn import GCNConv\n",
        "\n",
        "import torch_geometric.transforms as T\n",
        "from ogb.nodeproppred import PygNodePropPredDataset, Evaluator"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.7.0+cu126\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gbVqkDb2Z4J9",
        "outputId": "470abb68-1a08-45a0-cf92-ba267648a41f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Data(num_nodes=169343, edge_index=[2, 1166243], x=[169343, 128], node_year=[169343, 1], y=[169343, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0IK9z0wQIwzQ"
      },
      "source": [
        "## Load and Preprocess the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ibJ0ieoIwQM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb478c9d-431b-4b5c-b4f2-9e8a3614f9b1"
      },
      "source": [
        "dataset_name = 'ogbn-arxiv'\n",
        "dataset = PygNodePropPredDataset(name=dataset_name,\n",
        "                                transform=T.ToSparseTensor())\n",
        "data = dataset[0]\n",
        "\n",
        "# Make the adjacency matrix to symmetric\n",
        "# data.adj_t = data.adj_t.to_symmetric()\n",
        "data.adj_t = data.adj_t + data.adj_t.transpose(0,1).to_sparse_csr()\n",
        "# data.adj_t = data.adj_t.setdiag()  # Optionally set diagonal elements\n",
        "# Optionally set diagonal elements\n",
        "diag_mask = data.adj_t.crow_indices == data.adj_t.col_indices\n",
        "data.adj_t.values()[diag_mask] = 0\n",
        "\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "# If you use GPU, the device should be cuda\n",
        "print('Device: {}'.format(device))\n",
        "\n",
        "data = data.to(device)\n",
        "split_idx = dataset.get_idx_split()\n",
        "train_idx = split_idx['train'].to(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch_geometric/utils/sparse.py:277: UserWarning: Sparse CSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at /pytorch/aten/src/ATen/SparseCsrTensorImpl.cpp:53.)\n",
            "  adj = torch.sparse_csr_tensor(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.adj_t, data.adj_t.transpose(0,1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T08I9OdOh9Pm",
        "outputId": "747d2e06-d1a4-4c35-9f67-c948d77b29a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(crow_indices=tensor([      0,     291,     293,  ..., 2315576,\n",
              "                             2315596, 2315598]),\n",
              "        col_indices=tensor([   411,    640,   1162,  ..., 163274,  27824,\n",
              "                            158981]),\n",
              "        values=tensor([1., 1., 1.,  ..., 1., 1., 1.]), device='cuda:0',\n",
              "        size=(169343, 169343), nnz=2315598, layout=torch.sparse_csr),\n",
              " tensor(ccol_indices=tensor([      0,     291,     293,  ..., 2315576,\n",
              "                             2315596, 2315598]),\n",
              "        row_indices=tensor([   411,    640,   1162,  ..., 163274,  27824,\n",
              "                            158981]),\n",
              "        values=tensor([1., 1., 1.,  ..., 1., 1., 1.]), device='cuda:0',\n",
              "        size=(169343, 169343), nnz=2315598, layout=torch.sparse_csc))"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "split_idx"
      ],
      "metadata": {
        "id": "1kj7eZ9DxUi2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2d69459-37c1-4236-a489-dc038b0b7eaf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'train': tensor([     0,      1,      2,  ..., 169145, 169148, 169251]),\n",
              " 'valid': tensor([   349,    357,    366,  ..., 169185, 169261, 169296]),\n",
              " 'test': tensor([   346,    398,    451,  ..., 169340, 169341, 169342])}"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OgUA815bNJ8w"
      },
      "source": [
        "## GCN Model\n",
        "\n",
        "Now we will implement our GCN model!\n",
        "\n",
        "Please follow the figure below to implement the `forward` function.\n",
        "\n",
        "\n",
        "![test](https://drive.google.com/uc?id=128AuYAXNXGg7PIhJJ7e420DoPWKb-RtL)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IgspXTYpNJLA"
      },
      "source": [
        "class GCN(torch.nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim, num_layers,\n",
        "                 dropout, return_embeds=False):\n",
        "\n",
        "        super(GCN, self).__init__()\n",
        "\n",
        "        # A list of GCNConv layers\n",
        "        self.convs = None\n",
        "\n",
        "        # A list of 1D batch normalization layers\n",
        "        self.bns = None\n",
        "\n",
        "        # The log softmax layer\n",
        "        self.softmax = None\n",
        "        self.convs = torch.nn.ModuleList(\n",
        "            [GCNConv(in_channels = input_dim, out_channels=hidden_dim)] +\n",
        "            [GCNConv(in_channels = hidden_dim, out_channels=hidden_dim) for i in range(num_layers - 2)] +\n",
        "            [GCNConv(in_channels = hidden_dim, out_channels=output_dim)]\n",
        "            )\n",
        "        self.bns = torch.nn.ModuleList(\n",
        "            [torch.nn.BatchNorm1d(num_features=hidden_dim) for i in range(num_layers - 1)]\n",
        "            )\n",
        "        self.softmax = torch.nn.LogSoftmax(-1)\n",
        "\n",
        "        # Probability of an element getting zeroed\n",
        "        self.dropout = dropout\n",
        "\n",
        "        # Skip classification layer and return node embeddings\n",
        "        self.return_embeds = return_embeds\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        for conv in self.convs:\n",
        "            conv.reset_parameters()\n",
        "        for bn in self.bns:\n",
        "            bn.reset_parameters()\n",
        "\n",
        "    def forward(self, x, adj_t):\n",
        "\n",
        "        out = None\n",
        "\n",
        "\n",
        "        for conv, bn in zip(self.convs[:-1], self.bns):\n",
        "          x = F.relu(bn(conv(x, adj_t)))\n",
        "          if self.training:\n",
        "            x = F.dropout(x, self.dropout)\n",
        "        # layers = [torch.nn.Sequential(conv(x, adj_t), bn, F.relu, F.dropout(input = x, p =self.dropout)) if self.training else torch.nn.Sequential(conv, bn, F.relu) for conv, bn in zip(self.convs[:-1], self.bns)]\n",
        "        # x = layers(x)\n",
        "\n",
        "        # final layer\n",
        "        x = self.convs[-1](x, adj_t)\n",
        "        out = x if self.return_embeds else self.softmax(x)\n",
        "\n",
        "        return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FF1hnHUhO81e"
      },
      "source": [
        "def train(model, data, train_idx, optimizer, loss_fn):\n",
        "\n",
        "    model.train()\n",
        "    loss = 0\n",
        "\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    output = model(x = data.x, adj_t = data.adj_t) # Pass params to forward()\n",
        "    y_hat = output[train_idx]\n",
        "    y = data.y[train_idx]\n",
        "    loss = loss_fn(y_hat, y.reshape(-1))\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    return loss.item()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aJdlrJQhPBsK"
      },
      "source": [
        "# Test function here\n",
        "@torch.no_grad()\n",
        "def test(model, data, split_idx, evaluator, save_model_results=False):\n",
        "    # A function that tests the model by\n",
        "    # using the given split_idx and evaluator.\n",
        "    model.eval()\n",
        "\n",
        "    # The output of model on all data\n",
        "    out = None\n",
        "    out = model(data.x, data.adj_t)\n",
        "\n",
        "\n",
        "    y_pred = out.argmax(dim=-1, keepdim=True)\n",
        "\n",
        "    train_acc = evaluator.eval({\n",
        "        'y_true': data.y[split_idx['train']],\n",
        "        'y_pred': y_pred[split_idx['train']],\n",
        "    })['acc']\n",
        "    valid_acc = evaluator.eval({\n",
        "        'y_true': data.y[split_idx['valid']],\n",
        "        'y_pred': y_pred[split_idx['valid']],\n",
        "    })['acc']\n",
        "    test_acc = evaluator.eval({\n",
        "        'y_true': data.y[split_idx['test']],\n",
        "        'y_pred': y_pred[split_idx['test']],\n",
        "    })['acc']\n",
        "\n",
        "    if save_model_results:\n",
        "      print (\"Saving Model Predictions\")\n",
        "\n",
        "      data = {}\n",
        "      data['y_pred'] = y_pred.view(-1).cpu().detach().numpy()\n",
        "\n",
        "      df = pd.DataFrame(data=data)\n",
        "      # Save locally as csv\n",
        "      df.to_csv('ogbn-arxiv_node.csv', sep=',', index=False)\n",
        "\n",
        "\n",
        "    return train_acc, valid_acc, test_acc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o7F46xkuLiOL"
      },
      "source": [
        "args = {\n",
        "      'device': device,\n",
        "      'num_layers': 3,\n",
        "      'hidden_dim': 256,\n",
        "      'dropout': 0.5,\n",
        "      'lr': 0.01,\n",
        "      'epochs': 100,\n",
        "}\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dT8RyM2cPGxM"
      },
      "source": [
        "model = GCN(data.num_features, args['hidden_dim'],\n",
        "            dataset.num_classes, args['num_layers'],\n",
        "            args['dropout']).to(device)\n",
        "evaluator = Evaluator(name='ogbn-arxiv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qd5O5cnPPdVF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0cba208a-061f-4c9f-a170-42963814ce8c"
      },
      "source": [
        "# Please do not change these args\n",
        "# Training should take <10min using GPU runtime\n",
        "import copy\n",
        "# reset the parameters to initial random value\n",
        "model.reset_parameters()\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=args['lr'])\n",
        "loss_fn = F.nll_loss\n",
        "\n",
        "best_model = None\n",
        "best_valid_acc = 0\n",
        "\n",
        "for epoch in range(1, 1 + args[\"epochs\"]):\n",
        "  loss = train(model, data, train_idx, optimizer, loss_fn)\n",
        "  result = test(model, data, split_idx, evaluator)\n",
        "  train_acc, valid_acc, test_acc = result\n",
        "  if valid_acc > best_valid_acc:\n",
        "      best_valid_acc = valid_acc\n",
        "      best_model = copy.deepcopy(model)\n",
        "  print(f'Epoch: {epoch:02d}, '\n",
        "        f'Loss: {loss:.4f}, '\n",
        "        f'Train: {100 * train_acc:.2f}%, '\n",
        "        f'Valid: {100 * valid_acc:.2f}% '\n",
        "        f'Test: {100 * test_acc:.2f}%')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 01, Loss: 4.2866, Train: 25.76%, Valid: 29.27% Test: 26.29%\n",
            "Epoch: 02, Loss: 2.3808, Train: 24.61%, Valid: 21.59% Test: 26.72%\n",
            "Epoch: 03, Loss: 1.9075, Train: 22.98%, Valid: 16.72% Test: 18.02%\n",
            "Epoch: 04, Loss: 1.7705, Train: 29.13%, Valid: 27.46% Test: 26.75%\n",
            "Epoch: 05, Loss: 1.6497, Train: 39.98%, Valid: 37.94% Test: 34.52%\n",
            "Epoch: 06, Loss: 1.5593, Train: 42.50%, Valid: 38.20% Test: 35.44%\n",
            "Epoch: 07, Loss: 1.5043, Train: 42.92%, Valid: 38.13% Test: 38.38%\n",
            "Epoch: 08, Loss: 1.4599, Train: 43.06%, Valid: 40.02% Test: 45.51%\n",
            "Epoch: 09, Loss: 1.4066, Train: 41.16%, Valid: 36.19% Test: 41.39%\n",
            "Epoch: 10, Loss: 1.3694, Train: 40.30%, Valid: 34.43% Test: 38.95%\n",
            "Epoch: 11, Loss: 1.3471, Train: 40.52%, Valid: 33.98% Test: 38.34%\n",
            "Epoch: 12, Loss: 1.3193, Train: 42.04%, Valid: 35.04% Test: 39.32%\n",
            "Epoch: 13, Loss: 1.2948, Train: 44.68%, Valid: 37.99% Test: 42.15%\n",
            "Epoch: 14, Loss: 1.2693, Train: 47.29%, Valid: 41.48% Test: 45.73%\n",
            "Epoch: 15, Loss: 1.2556, Train: 49.36%, Valid: 45.63% Test: 49.64%\n",
            "Epoch: 16, Loss: 1.2376, Train: 50.77%, Valid: 47.78% Test: 51.93%\n",
            "Epoch: 17, Loss: 1.2229, Train: 51.56%, Valid: 48.75% Test: 52.70%\n",
            "Epoch: 18, Loss: 1.2088, Train: 52.61%, Valid: 49.83% Test: 53.67%\n",
            "Epoch: 19, Loss: 1.1947, Train: 53.95%, Valid: 51.29% Test: 54.93%\n",
            "Epoch: 20, Loss: 1.1851, Train: 55.17%, Valid: 52.79% Test: 56.36%\n",
            "Epoch: 21, Loss: 1.1777, Train: 56.03%, Valid: 53.95% Test: 57.27%\n",
            "Epoch: 22, Loss: 1.1639, Train: 56.83%, Valid: 54.90% Test: 58.25%\n",
            "Epoch: 23, Loss: 1.1544, Train: 57.79%, Valid: 55.98% Test: 59.33%\n",
            "Epoch: 24, Loss: 1.1492, Train: 59.02%, Valid: 57.53% Test: 60.54%\n",
            "Epoch: 25, Loss: 1.1412, Train: 60.03%, Valid: 58.60% Test: 61.40%\n",
            "Epoch: 26, Loss: 1.1307, Train: 61.16%, Valid: 59.77% Test: 62.31%\n",
            "Epoch: 27, Loss: 1.1195, Train: 61.96%, Valid: 60.68% Test: 62.79%\n",
            "Epoch: 28, Loss: 1.1152, Train: 62.87%, Valid: 61.75% Test: 63.69%\n",
            "Epoch: 29, Loss: 1.1093, Train: 63.90%, Valid: 62.99% Test: 64.55%\n",
            "Epoch: 30, Loss: 1.1019, Train: 64.95%, Valid: 64.66% Test: 65.37%\n",
            "Epoch: 31, Loss: 1.1006, Train: 65.74%, Valid: 65.35% Test: 66.05%\n",
            "Epoch: 32, Loss: 1.0917, Train: 66.34%, Valid: 66.12% Test: 66.59%\n",
            "Epoch: 33, Loss: 1.0879, Train: 66.70%, Valid: 66.58% Test: 67.03%\n",
            "Epoch: 34, Loss: 1.0794, Train: 66.80%, Valid: 66.49% Test: 67.29%\n",
            "Epoch: 35, Loss: 1.0747, Train: 66.77%, Valid: 66.42% Test: 67.35%\n",
            "Epoch: 36, Loss: 1.0726, Train: 67.08%, Valid: 66.54% Test: 67.50%\n",
            "Epoch: 37, Loss: 1.0670, Train: 67.53%, Valid: 66.84% Test: 67.92%\n",
            "Epoch: 38, Loss: 1.0585, Train: 68.17%, Valid: 67.40% Test: 68.31%\n",
            "Epoch: 39, Loss: 1.0585, Train: 68.87%, Valid: 68.10% Test: 68.72%\n",
            "Epoch: 40, Loss: 1.0509, Train: 69.45%, Valid: 68.79% Test: 69.16%\n",
            "Epoch: 41, Loss: 1.0488, Train: 69.98%, Valid: 69.38% Test: 69.51%\n",
            "Epoch: 42, Loss: 1.0442, Train: 70.21%, Valid: 69.75% Test: 69.55%\n",
            "Epoch: 43, Loss: 1.0411, Train: 70.29%, Valid: 69.96% Test: 69.57%\n",
            "Epoch: 44, Loss: 1.0380, Train: 70.25%, Valid: 70.00% Test: 69.77%\n",
            "Epoch: 45, Loss: 1.0334, Train: 70.02%, Valid: 69.65% Test: 69.77%\n",
            "Epoch: 46, Loss: 1.0312, Train: 69.79%, Valid: 69.13% Test: 69.47%\n",
            "Epoch: 47, Loss: 1.0305, Train: 69.85%, Valid: 69.24% Test: 69.53%\n",
            "Epoch: 48, Loss: 1.0263, Train: 70.19%, Valid: 69.56% Test: 69.71%\n",
            "Epoch: 49, Loss: 1.0216, Train: 70.45%, Valid: 70.01% Test: 69.71%\n",
            "Epoch: 50, Loss: 1.0168, Train: 70.67%, Valid: 70.14% Test: 69.61%\n",
            "Epoch: 51, Loss: 1.0149, Train: 70.82%, Valid: 70.27% Test: 69.71%\n",
            "Epoch: 52, Loss: 1.0119, Train: 70.94%, Valid: 70.34% Test: 69.89%\n",
            "Epoch: 53, Loss: 1.0057, Train: 70.97%, Valid: 70.33% Test: 70.03%\n",
            "Epoch: 54, Loss: 1.0058, Train: 71.19%, Valid: 70.43% Test: 70.13%\n",
            "Epoch: 55, Loss: 1.0020, Train: 71.41%, Valid: 70.65% Test: 70.22%\n",
            "Epoch: 56, Loss: 1.0005, Train: 71.55%, Valid: 70.82% Test: 70.11%\n",
            "Epoch: 57, Loss: 0.9985, Train: 71.50%, Valid: 70.86% Test: 70.03%\n",
            "Epoch: 58, Loss: 0.9972, Train: 71.37%, Valid: 70.79% Test: 70.22%\n",
            "Epoch: 59, Loss: 0.9917, Train: 71.36%, Valid: 70.85% Test: 70.36%\n",
            "Epoch: 60, Loss: 0.9925, Train: 71.49%, Valid: 70.98% Test: 70.25%\n",
            "Epoch: 61, Loss: 0.9881, Train: 71.65%, Valid: 70.68% Test: 69.48%\n",
            "Epoch: 62, Loss: 0.9871, Train: 71.62%, Valid: 70.20% Test: 68.75%\n",
            "Epoch: 63, Loss: 0.9840, Train: 71.75%, Valid: 70.44% Test: 69.17%\n",
            "Epoch: 64, Loss: 0.9824, Train: 71.93%, Valid: 70.73% Test: 69.78%\n",
            "Epoch: 65, Loss: 0.9788, Train: 72.08%, Valid: 70.86% Test: 70.00%\n",
            "Epoch: 66, Loss: 0.9782, Train: 72.15%, Valid: 71.02% Test: 70.22%\n",
            "Epoch: 67, Loss: 0.9754, Train: 72.18%, Valid: 71.18% Test: 70.43%\n",
            "Epoch: 68, Loss: 0.9753, Train: 72.16%, Valid: 71.24% Test: 70.54%\n",
            "Epoch: 69, Loss: 0.9707, Train: 72.23%, Valid: 71.14% Test: 70.18%\n",
            "Epoch: 70, Loss: 0.9683, Train: 72.16%, Valid: 70.00% Test: 68.05%\n",
            "Epoch: 71, Loss: 0.9675, Train: 72.11%, Valid: 69.91% Test: 67.67%\n",
            "Epoch: 72, Loss: 0.9682, Train: 72.32%, Valid: 70.86% Test: 69.38%\n",
            "Epoch: 73, Loss: 0.9646, Train: 72.37%, Valid: 71.42% Test: 70.55%\n",
            "Epoch: 74, Loss: 0.9638, Train: 72.44%, Valid: 71.37% Test: 70.75%\n",
            "Epoch: 75, Loss: 0.9606, Train: 72.53%, Valid: 71.33% Test: 70.23%\n",
            "Epoch: 76, Loss: 0.9579, Train: 72.48%, Valid: 71.01% Test: 69.78%\n",
            "Epoch: 77, Loss: 0.9569, Train: 72.60%, Valid: 71.24% Test: 70.59%\n",
            "Epoch: 78, Loss: 0.9546, Train: 72.75%, Valid: 71.50% Test: 70.88%\n",
            "Epoch: 79, Loss: 0.9522, Train: 72.85%, Valid: 71.66% Test: 70.71%\n",
            "Epoch: 80, Loss: 0.9515, Train: 72.96%, Valid: 71.55% Test: 70.24%\n",
            "Epoch: 81, Loss: 0.9499, Train: 72.97%, Valid: 71.72% Test: 70.98%\n",
            "Epoch: 82, Loss: 0.9491, Train: 72.85%, Valid: 71.48% Test: 71.06%\n",
            "Epoch: 83, Loss: 0.9439, Train: 72.73%, Valid: 71.43% Test: 71.00%\n",
            "Epoch: 84, Loss: 0.9447, Train: 72.88%, Valid: 71.54% Test: 70.47%\n",
            "Epoch: 85, Loss: 0.9455, Train: 72.90%, Valid: 71.02% Test: 69.36%\n",
            "Epoch: 86, Loss: 0.9378, Train: 73.03%, Valid: 71.23% Test: 69.64%\n",
            "Epoch: 87, Loss: 0.9376, Train: 73.09%, Valid: 71.42% Test: 70.28%\n",
            "Epoch: 88, Loss: 0.9373, Train: 73.17%, Valid: 71.38% Test: 70.23%\n",
            "Epoch: 89, Loss: 0.9379, Train: 73.15%, Valid: 71.37% Test: 70.25%\n",
            "Epoch: 90, Loss: 0.9351, Train: 73.14%, Valid: 71.41% Test: 70.26%\n",
            "Epoch: 91, Loss: 0.9326, Train: 73.35%, Valid: 71.61% Test: 70.27%\n",
            "Epoch: 92, Loss: 0.9313, Train: 73.33%, Valid: 71.29% Test: 69.61%\n",
            "Epoch: 93, Loss: 0.9327, Train: 73.27%, Valid: 71.09% Test: 69.38%\n",
            "Epoch: 94, Loss: 0.9315, Train: 73.37%, Valid: 71.61% Test: 70.22%\n",
            "Epoch: 95, Loss: 0.9247, Train: 73.56%, Valid: 71.84% Test: 70.75%\n",
            "Epoch: 96, Loss: 0.9262, Train: 73.55%, Valid: 71.88% Test: 70.93%\n",
            "Epoch: 97, Loss: 0.9261, Train: 73.60%, Valid: 71.80% Test: 70.47%\n",
            "Epoch: 98, Loss: 0.9240, Train: 73.66%, Valid: 71.49% Test: 69.86%\n",
            "Epoch: 99, Loss: 0.9200, Train: 73.68%, Valid: 71.42% Test: 69.69%\n",
            "Epoch: 100, Loss: 0.9204, Train: 73.75%, Valid: 71.70% Test: 70.31%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.makedirs('models', exist_ok=True)\n",
        "torch.save(best_model.state_dict(), 'models/best_model.pth')\n",
        "best_model.load_state_dict(torch.load('models/best_model.pth'))\n",
        "best_model.eval()  # Set the model to evaluation mode"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rC8301U4iGkY",
        "outputId": "ba6dda33-c03b-4923-a6c8-6d90194dc7e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GCN(\n",
              "  (convs): ModuleList(\n",
              "    (0): GCNConv(128, 256)\n",
              "    (1): GCNConv(256, 256)\n",
              "    (2): GCNConv(256, 40)\n",
              "  )\n",
              "  (bns): ModuleList(\n",
              "    (0-1): 2 x BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (softmax): LogSoftmax(dim=-1)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EqcextqOL2FX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1dda53a5-4836-49f2-b555-d5aa1e8b927b"
      },
      "source": [
        "best_result = test(best_model, data, split_idx, evaluator, save_model_results=True)\n",
        "train_acc, valid_acc, test_acc = best_result\n",
        "print(f'Best model: '\n",
        "      f'Train: {100 * train_acc:.2f}%, '\n",
        "      f'Valid: {100 * valid_acc:.2f}% '\n",
        "      f'Test: {100 * test_acc:.2f}%')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Model Predictions\n",
            "Best model: Train: 73.55%, Valid: 71.88% Test: 70.93%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Bonus: GNNExaplainer\n",
        "\n",
        "Author: Tommy Xie"
      ],
      "metadata": {
        "id": "V22MtUhuzYO3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.utils import to_edge_index\n",
        "\n",
        "# GNNExplainer in PyTorch Geometric (PyG) currently does not support inputs in the SparseTensor\n",
        "# Convert SparseTensor to edge_index and edge_attr\n",
        "edge_index, edge_attr = to_edge_index(data.adj_t)\n",
        "# Update the data object\n",
        "data.edge_index = edge_index\n",
        "data.edge_attr = edge_attr\n",
        "del edge_attr, edge_index"
      ],
      "metadata": {
        "id": "uU9p9Ygoe7hC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.explain import Explainer, GNNExplainer\n",
        "os.makedirs('figs_tabs', exist_ok=True)\n",
        "\n",
        "explainer = Explainer(\n",
        "    model=best_model,\n",
        "    algorithm=GNNExplainer(epochs=50),\n",
        "    explanation_type='model',\n",
        "    node_mask_type='attributes',\n",
        "    edge_mask_type='object',\n",
        "    model_config=dict(\n",
        "        mode='multiclass_classification',\n",
        "        task_level='node',\n",
        "        return_type='log_probs',\n",
        "    ),\n",
        ")\n",
        "node_index = 10\n",
        "\n",
        "\n",
        "explanation = explainer(data.x, data.edge_index, index=node_index)\n",
        "\n",
        "print(f'Generated explanations in {explanation.available_explanations}')\n",
        "\n",
        "path = 'figs_tabs/feature_importance.png'\n",
        "explanation.visualize_feature_importance(path, top_k=10)\n",
        "print(f\"Feature importance plot has been saved to '{path}'\")\n",
        "print(f'Generated explanations in {explanation.available_explanations}')"
      ],
      "metadata": {
        "id": "Lsyk5uSFzec7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f47dfb08-0b73-41fa-bffe-a400b9c1dcf7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature importance plot has been saved to 'feature_importance.png'\n",
            "Generated explanations in ['node_mask', 'edge_mask']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # perform explantion on a subgraph instead\n",
        "# from torch_geometric.utils import k_hop_subgraph\n",
        "# from torch_geometric.data import Data\n",
        "\n",
        "# # Parameters\n",
        "# node_idx = 10  # Node of interest\n",
        "# num_hops = 5   # Number of hops to include in the subgraph\n",
        "\n",
        "# subset, edge_index, mapping, edge_mask = k_hop_subgraph(\n",
        "#     node_idx=node_idx,\n",
        "#     num_hops=num_hops,\n",
        "#     edge_index=edge_index,\n",
        "#     relabel_nodes=True\n",
        "# )\n",
        "\n",
        "# # Create the subgraph data object\n",
        "# sub_data = Data(\n",
        "#     x=data.x[subset],\n",
        "#     edge_index=edge_index\n",
        "# )\n",
        "\n",
        "# # Apply GNNExplainer on the subgraph\n",
        "# explanation = explainer(sub_data.x, sub_data.edge_index, index=mapping)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        },
        "id": "IhOLi0sTcB5G",
        "outputId": "f74d2a8b-05d7-4b64-f645-16f8fed45588"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "OutOfMemoryError",
          "evalue": "CUDA out of memory. Tried to allocate 42.00 MiB. GPU 0 has a total capacity of 14.74 GiB of which 12.12 MiB is free. Process 218954 has 14.73 GiB memory in use. Of the allocated memory 14.41 GiB is allocated by PyTorch, and 183.62 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-88-ba39146ce92c>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# Create the subgraph data object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m sub_data = Data(\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0medge_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0medge_index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m )\n",
            "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 42.00 MiB. GPU 0 has a total capacity of 14.74 GiB of which 12.12 MiB is free. Process 218954 has 14.73 GiB memory in use. Of the allocated memory 14.41 GiB is allocated by PyTorch, and 183.62 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R8pOD6y80TyI"
      },
      "source": [
        "# 4) GNN: Graph Property Prediction\n",
        "\n",
        "In this section we will create a graph neural network for graph property prediction (graph classification).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vRg5VOEdQTa4"
      },
      "source": [
        "## Load and preprocess the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LXb-O5QUIgTH"
      },
      "source": [
        "from ogb.graphproppred import PygGraphPropPredDataset, Evaluator\n",
        "from torch_geometric.data import DataLoader\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "# Load the dataset\n",
        "dataset = PygGraphPropPredDataset(name='ogbg-molhiv')\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print('Device: {}'.format(device))\n",
        "\n",
        "split_idx = dataset.get_idx_split()\n",
        "\n",
        "# Check task type\n",
        "print('Task type: {}'.format(dataset.task_type))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7cHHbgW1c5hi"
      },
      "source": [
        "# Load the dataset splits into corresponding dataloaders\n",
        "# We will train the graph classification task on a batch of 32 graphs\n",
        "# Shuffle the order of graphs for training set\n",
        "train_loader = DataLoader(dataset[split_idx[\"train\"]], batch_size=32, shuffle=True, num_workers=0)\n",
        "valid_loader = DataLoader(dataset[split_idx[\"valid\"]], batch_size=32, shuffle=False, num_workers=0)\n",
        "test_loader = DataLoader(dataset[split_idx[\"test\"]], batch_size=32, shuffle=False, num_workers=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AYrSnOj0Y4DK"
      },
      "source": [
        "# Please do not change the args\n",
        "args = {\n",
        "    'device': device,\n",
        "    'num_layers': 5,\n",
        "    'hidden_dim': 256,\n",
        "    'dropout': 0.5,\n",
        "    'lr': 0.001,\n",
        "    'epochs': 30,\n",
        "}\n",
        "args"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7WLhguSTeazy"
      },
      "source": [
        "## Graph Prediction Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u05Z14TRYPGn"
      },
      "source": [
        "### Graph Mini-Batching\n",
        "Before diving into the actual model, we introduce the concept of mini-batching with graphs. In order to parallelize the processing of a mini-batch of graphs, PyG combines the graphs into a single disconnected graph data object (*torch_geometric.data.Batch*). *torch_geometric.data.Batch* inherits from *torch_geometric.data.Data* (introduced earlier) and contains an additional attribute called `batch`.\n",
        "\n",
        "The `batch` attribute is a vector mapping each node to the index of its corresponding graph within the mini-batch:\n",
        "\n",
        "    batch = [0, ..., 0, 1, ..., n - 2, n - 1, ..., n - 1]\n",
        "\n",
        "This attribute is crucial for associating which graph each node belongs to and can be used to e.g. average the node embeddings for each graph individually to compute graph level embeddings.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pcic9NNU3nGK"
      },
      "source": [
        "### Implemention\n",
        "Now, we have all of the tools to implement a GCN Graph Prediction model!  \n",
        "\n",
        "We will reuse the existing GCN model to generate `node_embeddings` and then use  `Global Pooling` over the nodes to create graph level embeddings that can be used to predict properties for the each graph. Remeber that the `batch` attribute will be essential for performining Global Pooling over our mini-batch of graphs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3_Kq3zyjeZ22"
      },
      "source": [
        "from ogb.graphproppred.mol_encoder import AtomEncoder\n",
        "from torch_geometric.nn import global_add_pool, global_mean_pool\n",
        "\n",
        "### GCN to predict graph property\n",
        "class GCN_Graph(torch.nn.Module):\n",
        "    def __init__(self, hidden_dim, output_dim, num_layers, dropout):\n",
        "        super(GCN_Graph, self).__init__()\n",
        "\n",
        "        # Load encoders for Atoms in molecule graphs\n",
        "        self.node_encoder = AtomEncoder(hidden_dim)\n",
        "\n",
        "        # Node embedding model\n",
        "        # Note that the input_dim and output_dim are set to hidden_dim\n",
        "        self.gnn_node = GCN(hidden_dim, hidden_dim,\n",
        "            hidden_dim, num_layers, dropout, return_embeds=True)\n",
        "\n",
        "        self.pool = None\n",
        "\n",
        "\n",
        "        self.pool = global_mean_pool\n",
        "\n",
        "        # Output layer\n",
        "        self.linear = torch.nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "\n",
        "    def reset_parameters(self):\n",
        "      self.gnn_node.reset_parameters()\n",
        "      self.linear.reset_parameters()\n",
        "\n",
        "    def forward(self, batched_data):\n",
        "\n",
        "        # Extract important attributes of our mini-batch\n",
        "        x, edge_index, batch = batched_data.x, batched_data.edge_index, batched_data.batch\n",
        "        embed = self.node_encoder(x)\n",
        "\n",
        "        out = None\n",
        "        node_embed = self.gnn_node(embed, edge_index)\n",
        "        features = self.pool(node_embed, batch)\n",
        "        out = self.linear(features)\n",
        "\n",
        "        return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FJjnGuMSbjX0"
      },
      "source": [
        "def train(model, device, data_loader, optimizer, loss_fn):\n",
        "    # a function that trains your model by\n",
        "    # using the given optimizer and loss_fn.\n",
        "    model.train()\n",
        "    loss = 0\n",
        "\n",
        "    for step, batch in enumerate(tqdm(data_loader, desc=\"Iteration\")):\n",
        "      batch = batch.to(device)\n",
        "\n",
        "      if batch.x.shape[0] == 1 or batch.batch[-1] == 0:\n",
        "          pass\n",
        "      else:\n",
        "        ## ignore nan targets (unlabeled) when computing training loss.\n",
        "        is_labeled = batch.y == batch.y\n",
        "        optimizer.zero_grad()\n",
        "        y_hat = model(batch)[is_labeled]\n",
        "        y = batch.y[is_labeled]\n",
        "        loss = loss_fn(y_hat, y.float())\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    return loss.item()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ztPHXq_Gzn7U"
      },
      "source": [
        "# The evaluation function\n",
        "def eval(model, device, loader, evaluator, save_model_results=False, save_file=None):\n",
        "    model.eval()\n",
        "    y_true = []\n",
        "    y_pred = []\n",
        "\n",
        "    for step, batch in enumerate(tqdm(loader, desc=\"Iteration\")):\n",
        "        batch = batch.to(device)\n",
        "\n",
        "        if batch.x.shape[0] == 1:\n",
        "            pass\n",
        "        else:\n",
        "            with torch.no_grad():\n",
        "                pred = model(batch)\n",
        "\n",
        "            y_true.append(batch.y.view(pred.shape).detach().cpu())\n",
        "            y_pred.append(pred.detach().cpu())\n",
        "\n",
        "    y_true = torch.cat(y_true, dim = 0).numpy()\n",
        "    y_pred = torch.cat(y_pred, dim = 0).numpy()\n",
        "\n",
        "    input_dict = {\"y_true\": y_true, \"y_pred\": y_pred}\n",
        "\n",
        "    if save_model_results:\n",
        "        print (\"Saving Model Predictions\")\n",
        "\n",
        "        # Create a pandas dataframe with a two columns\n",
        "        # y_pred | y_true\n",
        "        data = {}\n",
        "        data['y_pred'] = y_pred.reshape(-1)\n",
        "        data['y_true'] = y_true.reshape(-1)\n",
        "\n",
        "        df = pd.DataFrame(data=data)\n",
        "        # Save to csv\n",
        "        df.to_csv('ogbg-molhiv_graph_' + save_file + '.csv', sep=',', index=False)\n",
        "\n",
        "    return evaluator.eval(input_dict)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MR1wQ4hMZeMw"
      },
      "source": [
        "model = GCN_Graph(args['hidden_dim'],\n",
        "            dataset.num_tasks, args['num_layers'],\n",
        "            args['dropout']).to(device)\n",
        "evaluator = Evaluator(name='ogbg-molhiv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJGTNZiuZy0A"
      },
      "source": [
        "# Please do not change these args\n",
        "# Training should take <10min using GPU runtime\n",
        "import copy\n",
        "\n",
        "model.reset_parameters()\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=args['lr'])\n",
        "loss_fn = torch.nn.BCEWithLogitsLoss()\n",
        "\n",
        "best_model = None\n",
        "best_valid_acc = 0\n",
        "\n",
        "for epoch in range(1, 1 + args[\"epochs\"]):\n",
        "  print('Training...')\n",
        "  loss = train(model, device, train_loader, optimizer, loss_fn)\n",
        "\n",
        "  print('Evaluating...')\n",
        "  train_result = eval(model, device, train_loader, evaluator)\n",
        "  val_result = eval(model, device, valid_loader, evaluator)\n",
        "  test_result = eval(model, device, test_loader, evaluator)\n",
        "\n",
        "  train_acc, valid_acc, test_acc = train_result[dataset.eval_metric], val_result[dataset.eval_metric], test_result[dataset.eval_metric]\n",
        "  if valid_acc > best_valid_acc:\n",
        "      best_valid_acc = valid_acc\n",
        "      best_model = copy.deepcopy(model)\n",
        "  print(f'Epoch: {epoch:02d}, '\n",
        "        f'Loss: {loss:.4f}, '\n",
        "        f'Train: {100 * train_acc:.2f}%, '\n",
        "        f'Valid: {100 * valid_acc:.2f}% '\n",
        "        f'Test: {100 * test_acc:.2f}%')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oq5QaG21dOOO"
      },
      "source": [
        "\n",
        "train_acc = eval(best_model, device, train_loader, evaluator)[dataset.eval_metric]\n",
        "valid_acc = eval(best_model, device, valid_loader, evaluator, save_model_results=True, save_file=\"valid\")[dataset.eval_metric]\n",
        "test_acc  = eval(best_model, device, test_loader, evaluator, save_model_results=True, save_file=\"test\")[dataset.eval_metric]\n",
        "\n",
        "print(f'Best model: '\n",
        "    f'Train: {100 * train_acc:.2f}%, '\n",
        "    f'Valid: {100 * valid_acc:.2f}% '\n",
        "    f'Test: {100 * test_acc:.2f}%')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gBi_t8n0iZ4P"
      },
      "source": [
        "Experiment with the two other global pooling layers in Pytorch Geometric."
      ]
    }
  ]
}